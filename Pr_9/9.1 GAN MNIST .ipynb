{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e04d0b3",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0caac02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following the following https://github.com/Zackory/Keras-MNIST-GAN/blob/master/mnist_gan.py\n",
    "# with minor modifications\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6902f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "image shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print('image shape', x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d22c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  784\n"
     ]
    }
   ],
   "source": [
    "input_dim = 784\n",
    "x_train = x_train.reshape(60000, input_dim)\n",
    "print('input shape: ', x_train.shape[1])\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5  # normilization [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489be9e1",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990fb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model =  keras.Sequential()\n",
    "    model.add(layers.Dense(1024, input_dim=input_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "        \n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc8a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "def build_generator():\n",
    "    model =  keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_dim=latent_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(layers.Dense(input_dim, activation='tanh'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1afc086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = keras.Input(shape=(latent_dim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = keras.Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optim)\n",
    "    return gan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd82ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "generator = build_generator()\n",
    "\n",
    "# Combined network\n",
    "discriminator.trainable = False\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = keras.Model(inputs=gan_input, outputs=gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63061ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, generator):\n",
    "    num_of_images = 10\n",
    "    noise = np.random.normal(0, 1, size=[num_of_images, latent_dim])\n",
    "    generated_images=generator.predict(noise).reshape(num_of_images, 28, 28)\n",
    "    plt.figure()\n",
    "    for i in range(num_of_images):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(generated_images[i], cmap = 'gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dfd5e",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf26da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim_losses = []\n",
    "\n",
    "def train_model(epochs, batch_size):\n",
    "    num_batches = int(x_train.shape[0]/batch_size)\n",
    "    for ep in range(epochs+1):\n",
    "        for i in range(num_batches):\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "            image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n",
    "            \n",
    "             # Generate fake MNIST images\n",
    "            generated_images = generator.predict(noise)\n",
    "            X = np.concatenate([image_batch, generated_images])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size] = 0.9  # (instead of 1.0) sort of trick in GAN training, so called label smoothing\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "            discrim_losses.append(d_loss)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "        if ep % 20 == 0:\n",
    "            print('epoch: ', ep)\n",
    "            plot_generated_images(ep, generator)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "train_model(epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(discrim_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88247c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
